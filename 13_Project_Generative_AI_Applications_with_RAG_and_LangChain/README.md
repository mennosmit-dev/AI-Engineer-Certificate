# Generative AI Applications with RAG & LangChain â€“ Project Implementations

This folder contains applied generative AI systems built using Retrieval-Augmented Generation (RAG) 
and LangChain during the **IBM AI Engineering Professional Certificate**.

The focus of this module was designing production-style LLM applications integrating 
document loaders, embeddings, vector databases, retrievers, and interactive interfaces.

---

## ðŸ§  Overview

Key areas explored:

- Document ingestion and preprocessing pipelines
- Text splitting and chunk optimization
- Embedding generation and vector database configuration
- Advanced retriever strategies (Multi-Query, Self-Query, Parent Document)
- RAG system integration with interactive UIs
- End-to-end QA application development

These projects represent applied LLM system design and real-world automation workflows.

---

## ðŸ“‚ Selected Implementations

### ðŸ”¹ Document Processing & Embeddings

- `langchain_doc_loaders.py`  
  Unified PDFs, Word, CSV, JSON, and web sources into standardized pipelines.  
  Reduced preprocessing time by **65%**.

- `text_splitting_rag.py`  
  Optimized chunking strategies for improved retrieval performance.  
  Increased retrieval relevance by **35%** and reduced latency by **25%**.

<img src="Images/splitter.png" width="220"/>

- `vector_db_embeddings.py`  
  Configured **ChromaDB** and **FAISS** for scalable document retrieval.  
  Improved information retrieval speed by **70%**.

<img src="Images/vectordb.png" width="240"/>

---

### ðŸ”¹ Retriever Engineering

- `document_retriever_langchain.py`  
  Implemented multiple retriever strategies:
  - Vector Store Retriever  
  - Multi-Query Retriever  
  - Self-Querying Retriever  
  - Parent Document Retriever  

  Improved retrieval precision by **40%**.

---

### ðŸ”¹ LLM Interfaces & QA Systems

- `gradio_llm_interface.py`  
  Built an interactive Gradio-based chatbot interface.

<img src="Images/datascience.png" width="240"/>

- `qa_bot_langchain.py`  
  End-to-end QA bot integrating loaders, splitters, embeddings, 
  vector DBs, and retrievers.  
  Improved document query accuracy by **45%** and reduced manual search time by **60%**.

<img src="Images/QA_bot.png" width="240"/>

---

### ðŸ”¹ Final Project â€“ RAG Research Assistant

- `rag_research_assistant`  
  Built an AI-powered RAG assistant for scientific paper summarization and querying.

  Architecture:
  - LangChain workflows
  - Embedding generation
  - Vector database indexing
  - Intelligent retriever configuration

  Results:
  - Improved research efficiency by **65%**
  - Reduced literature review time by 50%
  - Final grade: **92/100**

---

## ðŸ”§ Tools & Libraries

Python â€¢ LangChain â€¢ Hugging Face â€¢ watsonx â€¢ ChromaDB â€¢ FAISS â€¢ Gradio

---

## ðŸ“Œ Context

This module represents the applied RAG system engineering component of the  
IBM AI Engineering Professional Certificate, integrating transformer fine-tuning, 
alignment techniques, and retrieval pipelines into practical AI applications.
