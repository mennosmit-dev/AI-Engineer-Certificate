!pip install tensorflow_cpu==2.18.0
!pip install matplotlib==3.9.2
print("==== All required libraries are installed =====")

"""#### Suppress the tensorflow warning messages
We use the following code to  suppress the warning messages due to use of CPU architechture for tensoflow.
You may want to **comment out** these lines if you are using the GPU architechture
"""
import os
os.environ['TF_ENABLE_ONEDNN_OPTS'] = '0'
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'

"""## Import Keras and Packages
### Import the libraries.
There might be some warning messages related to floating point round off errors and lack of GPU and other compiler related options. You can ignore these warnings and proceed.
"""
import keras

from keras.models import Sequential
from keras.layers import Dense
from keras.layers import Input
from keras.utils import to_categorical

"""Since we are dealing we images, let's also import the Matplotlib scripting layer in order to view the images.
"""
import matplotlib.pyplot as plt

"""The Keras library conveniently includes the MNIST dataset as part of its API. You can check other datasets within the Keras library [here](https://keras.io/datasets/).
So, let's load the MNIST dataset from the Keras library. The dataset is readily divided into a training set and a test set.
"""
from keras.datasets import mnist
(X_train, y_train), (X_test, y_test) = mnist.load_data()

"""Let's confirm the number of images in each set. According to the dataset's documentation, we should have 60000 images in X_train and 10000 images in the X_test.
"""
X_train.shape

"""The first number in the output tuple is the number of images, and the other two numbers are the size of the images in datset. So, each image is 28 pixels by 28 pixels.
Let's visualize the first image in the training set using Matplotlib's scripting layer.
"""
plt.imshow(X_train[0])

"""With conventional neural networks, we cannot feed in the image as input as is. So we need to flatten the images into one-dimensional vectors, each of size 1 x (28 x 28) = 1 x 784.
"""
num_pixels = X_train.shape[1] * X_train.shape[2] # find size of one-dimensional vector
X_train = X_train.reshape(X_train.shape[0], num_pixels).astype('float32') # flatten training images
X_test = X_test.reshape(X_test.shape[0], num_pixels).astype('float32') # flatten test images

"""Since pixel values can range from 0 to 255, let's normalize the vectors to be between 0 and 1.
"""
X_train = X_train / 255
X_test = X_test / 255

"""Finally, before we start building our model, remember that for classification we need to divide our target variable into categories. We use the to_categorical function from the Keras Utilities package.
"""
y_train = to_categorical(y_train)
y_test = to_categorical(y_test)
num_classes = y_test.shape[1]
print(num_classes)

"""## Build a Neural Network
"""
def classification_model():
    model = Sequential()
    model.add(Input(shape=(num_pixels,)))
    model.add(Dense(num_pixels, activation='relu'))
    model.add(Dense(100, activation='relu'))
    model.add(Dense(num_classes, activation='softmax'))

    # compile model
    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])
    return model

"""## Train and Test the Network
"""
model = classification_model()
model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, verbose=2)
scores = model.evaluate(X_test, y_test, verbose=0)

"""Let's print the accuracy and the corresponding error.
"""
print('Accuracy: {}% \n Error: {}'.format(scores[1], 1 - scores[1]))

"""Just running 10 epochs could actually take over 20 minutes. But enjoy the results as they are getting generated.
Sometimes, you cannot afford to retrain your model everytime you want to use it, especially if you are limited on computational resources and training your model can take a long time. Therefore, with the Keras library, you can save your model after training. To do that, we use the save method.
"""
model.save('classification_model.keras')

"""Since our model contains multidimensional arrays of data, then models are usually saved as .keras files.
When you are ready to use your model again, you use the load_model function from <strong>keras.saving</strong>.
"""
pretrained_model = keras.saving.load_model('classification_model.keras')

"""Practice Exercise 1
Create a neural network model with 6 dense layers and compare its accuracy
"""
def classification_six_layers():
    model = Sequential()
    model.add(Input(shape=(num_pixels,)))
    model.add(Dense(num_pixels, activation='relu'))
    model.add(Dense(100, activation='relu'))
    model.add(Dense(100, activation='relu'))
    model.add(Dense(100, activation='relu'))
    model.add(Dense(100, activation='relu'))
    model.add(Dense(num_classes, activation='softmax'))
    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\
    return model

model = classification_six_layers()
model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, verbose=2)
scores = model.evaluate(X_test, y_test, verbose=0)
print('Accuracy: {}% \n Error: {}'.format(scores[1], 1 - scores[1]))

"""Practice Exercise 2
Now, load the the earlier saved model, train it further for 10 more epochs and check the accuracy
"""
pretrained_model = keras.saving.load_model('classification_model.keras')
pretrained_model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, verbose=2)
scores_20_epochs = pretrained_model.evaluate(X_test, y_test, verbose=0)
print('Accuracy_10_epochs: {}% \n Accuracy_20_epochs: {}'.format(scores[1], scores_20_epochs[1]))

### Thank you for completing this lab!

This notebook was created by [Alex Aklson](https://www.linkedin.com/in/aklson/). I hope you found this lab interesting and educational. Feel free to contact me if you have any questions!

<!--
## Change Log

|  Date (YYYY-MM-DD) |  Version | Changed By  |  Change Description |
|---|---|---|---|
| 2024-11-20  | 3.0  |   Aman   |  Updated the library versions to current |
| 2020-09-21  | 2.0  | Srishti  |  Migrated Lab to Markdown and added to course repo in GitLab |



<hr>

## <h3 align="center"> Â© IBM Corporation. All rights reserved. <h3/>

## <h3 align="center"> &#169; IBM Corporation. All rights reserved. <h3/>
"""
