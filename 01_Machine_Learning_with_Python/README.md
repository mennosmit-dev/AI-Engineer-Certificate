# Machine Learning with Python â€“ Project Implementations

This folder contains foundational machine learning projects completed as part of the  
**IBM AI Engineer Professional Certificate**.  

The focus here is on building strong practical intuition for classical ML algorithms, 
model evaluation, feature engineering, and pipeline design â€” forming the statistical 
and modeling foundation behind my applied ML and reinforcement learning work.

---

## ðŸ§  Overview

Implemented a wide range of supervised and unsupervised learning techniques, including:

- Regression and classification models (Logistic Regression, SVM, KNN, Trees, Random Forest, XGBoost)
- Clustering methods (K-Means, DBSCAN, HDBSCAN)
- Dimensionality reduction (PCA, t-SNE, UMAP)
- Regularization (Ridge, Lasso)
- End-to-end pipelines with GridSearchCV
- Model evaluation using ROC-AUC, F1-score, confusion matrices, and clustering metrics

Libraries used: Scikit-learn, Pandas, NumPy, Matplotlib.

---

## ðŸ“‚ Selected Implementations

### ðŸ”¹ Regression & Classification

- `simple_linear_regression.py` â€“ COâ‚‚ prediction using linear regression (RÂ²: 0.68)  
- `multiple-linear-regression` â€“ Multi-feature regression (RÂ²: 0.89)  
- `logistic_regression` â€“ Telecom churn prediction  
- `multi_class_classification.py` â€“ Obesity classification (OvA â†’ OvO improved accuracy 76% â†’ 92%)  
- `decision_trees.py` â€“ Drug prescription classifier (98.3% accuracy)  
- `decision_tree_svm_ccfraud.py` â€“ Credit card fraud detection (SVM ROC-AUC: 0.986)

---

### ðŸ”¹ Tree-Based Models & Ensembles

- `random__forests__xgboost.py` â€“ Housing price prediction (XGBoost MSE: 0.2226)  
- `regression_trees_taxi_tip.py` â€“ Tree-based regression with noise analysis  
- `evaluating_random_forest.py` â€“ Feature importance & model diagnostics  

---

### ðŸ”¹ Unsupervised Learning & Dimensionality Reduction

- `k-means-customer-seg.py` â€“ Customer segmentation  
- `comparing_dbscan_hdbscan.py` â€“ Density-based clustering comparison  
- `pca.py` â€“ Principal component analysis (72% variance explained)  
- `t-sne_umap.py` â€“ Visualization of high-dimensional feature spaces  

---

### ðŸ”¹ Model Evaluation & Pipelines

- `evaluating_classification_models.py` â€“ Breast cancer classification benchmarking  
- `ml_pipelines_and_gridsearchcv.py` â€“ Pipeline design with hyperparameter tuning  
- `regularization_in_linearregression.py` â€“ Ridge & Lasso feature selection  

---

### ðŸ”¹ Applied Projects

- `practice_project` â€“ Titanic survival prediction (Logistic Regression outperformed RF)  
- `finalproject_ausweather_.py` â€“ Rainfall prediction pipeline (RF accuracy: 83%)

---

## ðŸ”§ Tools & Libraries

Python â€¢ Scikit-learn â€¢ Pandas â€¢ NumPy â€¢ Matplotlib â€¢ Jupyter

---

## ðŸ“Œ Context

This module forms the classical ML foundation within the  
IBM AI Engineering Professional Certificate and complements my work in deep learning, reinforcement learning, and production ML systems.
